# ===============================================
# build_features_v3_behavior.py
# åŠŸèƒ½ï¼š
#   1. å¾ž acct_transaction.csv å»ºç«‹å¸³è™Ÿç´šç‰¹å¾µ
#   2. æ–°å¢žè¡Œç‚ºï¼æ™‚é–“ï¼é‡‘é¡ï¼é€šé“ç­‰å‹•æ…‹ç‰¹å¾µ
#   3. ä¿®æ­£æ—¥æœŸæ ¼å¼è­¦å‘Š + è™•ç† UNK é¡žåˆ¥
#   4. è¼¸å‡ºä¹¾æ·¨å¯ç”¨æ–¼ LightGBM çš„æ•¸å€¼ç‰¹å¾µ
# Step 2ï¸âƒ£ è£½ä½œ 1:1 è¨“ç·´é›†
#python v3/prepare_trainset_balanced_v3.py

# Step 3ï¸âƒ£ è¨“ç·´æ¨¡åž‹
#python v3/train_model_LGBM_v3.py

# Step 4ï¸âƒ£ é æ¸¬æ¯”è³½å¸³è™Ÿ
#python v3/predict_accounts_v3.py

# ===============================================

import pandas as pd
import numpy as np
import os


def build_features_v3(input_file: str, output_dir: str = "feature_data_v3"):
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "account_features.csv")

    print(f"ðŸ“‚ è®€å–äº¤æ˜“è³‡æ–™ï¼š{input_file}")
    df = pd.read_csv(input_file)

    # ========== é¡žåˆ¥æ¬„ä½æ¸…ç† ==========
    print("ðŸ§¹ æ¸…ç†é¡žåˆ¥æ¬„ä½ï¼ˆUNK / NaN è½‰æ›ï¼‰ ...")
    cat_cols = ["from_acct_type", "to_acct_type", "currency_type", "channel_type"]
    for c in cat_cols:
        if c in df.columns:
            df[c] = df[c].fillna("UNK").astype(str)
            df[c] = df[c].replace("UNK", "-1")  # ä¿ç•™æœªçŸ¥é¡žåˆ¥ç‚º -1

    # ========== æ–°å¢ž is_unk æ¨™è¨˜ ==========
    df["is_channel_unk"] = (df["channel_type"] == "-1").astype(int)
    df["is_toacct_unk"] = (df["to_acct_type"] == "-1").astype(int)

    # ========== æ—¥æœŸæ™‚é–“è™•ç†ï¼ˆä¿®æ­£è­¦å‘Šï¼‰ ==========
    print("ðŸ•’ è™•ç†æ—¥æœŸèˆ‡æ™‚é–“æ¬„ä½ ...")
    base_date = pd.Timestamp("2020-01-01")
    df["txn_datetime"] = base_date + pd.to_timedelta(df["txn_date"].astype(int), unit="D")
    df["txn_datetime"] += pd.to_timedelta(df["txn_time"])

    # ========== åŸºæœ¬çµ±è¨ˆç‰¹å¾µ ==========
    print("ðŸ“Š å»ºç«‹åŸºæœ¬äº¤æ˜“çµ±è¨ˆ ...")
    g = df.groupby("from_acct")
    from_feat = g["txn_amt"].agg(
        txn_count="count",
        total_amt="sum",
        avg_amt="mean",
        max_amt="max",
        min_amt="min",
        std_amt="std"
    ).reset_index()

    # ========== æ™‚é–“è¡Œç‚ºç‰¹å¾µ ==========
    print("â° åŠ å…¥æ™‚é–“è¡Œç‚ºç‰¹å¾µ ...")
    txn_time_feat = g["txn_datetime"].agg(first_txn="min", last_txn="max")
    txn_time_feat["active_days"] = (txn_time_feat["last_txn"] - txn_time_feat["first_txn"]).dt.days + 1
    txn_time_feat = txn_time_feat.reset_index()
    from_feat = from_feat.merge(txn_time_feat, on="from_acct", how="left")
    from_feat["txn_per_day"] = from_feat["txn_count"] / from_feat["active_days"].replace(0, 1)

    # å¤œé–“äº¤æ˜“æ¯”ä¾‹
    df["hour"] = pd.to_datetime(df["txn_time"], format="%H:%M:%S", errors="coerce").dt.hour
    df["is_night"] = df["hour"].apply(lambda x: 1 if x >= 22 or x < 6 else 0)
    night_ratio = g["is_night"].mean().reset_index().rename(columns={"is_night": "night_txn_ratio"})
    from_feat = from_feat.merge(night_ratio, on="from_acct", how="left")

    # ========== è‡ªè½‰èˆ‡é‡è¤‡å°è±¡ç‰¹å¾µ ==========
    print("ðŸ” åˆ†æžè‡ªè½‰èˆ‡é‡è¤‡å°è±¡ç‰¹å¾µ ...")
    df["is_self_txn"] = (df["from_acct"] == df["to_acct"]).astype(int)
    self_ratio = g["is_self_txn"].mean().reset_index().rename(columns={"is_self_txn": "self_txn_ratio"})
    from_feat = from_feat.merge(self_ratio, on="from_acct", how="left")

    # é‡è¤‡å°æ‰‹æ¯”ä¾‹
    to_count = g["to_acct"].count().reset_index(name="to_txn_total")
    unique_to = g["to_acct"].nunique().reset_index(name="to_acct_nunique")
    repeat_ratio = to_count.merge(unique_to, on="from_acct")
    repeat_ratio["repeat_partner_ratio"] = 1 - (repeat_ratio["to_acct_nunique"] / repeat_ratio["to_txn_total"])
    from_feat = from_feat.merge(repeat_ratio, on="from_acct", how="left")

    # ========== é‡‘é¡ç•°å¸¸åº¦ç‰¹å¾µ ==========
    print("ðŸ’° åŠ å…¥é‡‘é¡ç•°å¸¸åº¦ç‰¹å¾µ ...")
    from_feat["max_to_avg"] = from_feat["max_amt"] / (from_feat["avg_amt"] + 1e-5)
    from_feat["amount_cv"] = from_feat["std_amt"] / (from_feat["avg_amt"] + 1e-5)

    # ========== é€šé“å¤šæ¨£æ€§ ==========
    print("ðŸŒ é€šé“å¤šæ¨£æ€§ç‰¹å¾µ ...")
    channel_div = g["channel_type"].nunique().reset_index().rename(columns={"channel_type": "channel_nunique"})
    from_feat = from_feat.merge(channel_div, on="from_acct", how="left")

    # ========== å°æ‰‹å¸³æˆ¶å¤šæ¨£æ€§ ==========
    print("ðŸ”— å°æ‰‹å¸³æˆ¶å¤šæ¨£æ€§ ...")
    from_feat["partner_diversity"] = from_feat["to_acct_nunique"] / from_feat["txn_count"].replace(0, 1)

    # ========== UNK é¡žåˆ¥æ¯”ä¾‹ç‰¹å¾µ ==========
    print("â“ åŠ å…¥æœªçŸ¥é¡žåˆ¥æ¯”ä¾‹ç‰¹å¾µ ...")
    unk_feat = df.groupby("from_acct")[["is_channel_unk", "is_toacct_unk"]].mean().reset_index()
    from_feat = from_feat.merge(unk_feat, on="from_acct", how="left")

    # ========== è¼¸å‡º ==========
    from_feat.rename(columns={"from_acct": "acct_id"}, inplace=True)
    from_feat.fillna(0, inplace=True)
    from_feat.to_csv(output_file, index=False)

    print(f"âœ… å®Œæˆï¼Œå…± {len(from_feat)} ç­†å¸³è™Ÿç‰¹å¾µ")
    print(f"ðŸ’¾ å·²è¼¸å‡ºè‡³ï¼š{output_file}")


if __name__ == "__main__":
    input_path = "dataset/acct_transaction.csv"
    build_features_v3(input_path)
