# ==========================================================
# train_model_LGBM_v3_dual.py
# åŠŸèƒ½ï¼š
#   âœ… ä½¿ç”¨é›™å‘ç‰¹å¾µè¡¨è¨“ç·´ LightGBM æ¨¡å‹
#   âœ… è‡ªå‹•åµæ¸¬ GPU / CPU
#   âœ… è‡ªå‹•æ‰¾å‡ºæœ€ä½³é–¾å€¼ï¼ˆF1 æœ€å¤§åŒ–ï¼‰
#   âœ… å„²å­˜æ¨¡å‹ + ç‰¹å¾µé‡è¦åº¦ + æœ€ä½³é–¾å€¼
# ==========================================================

import pandas as pd
import lightgbm as lgb
import joblib
import os
import time
import json
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    f1_score, precision_score, recall_score, accuracy_score, confusion_matrix
)

# ======================
# è·¯å¾‘è¨­å®š
# ======================
train_file = "train_data_v3/train_data.csv"
output_dir = "train_data_v3"
os.makedirs(output_dir, exist_ok=True)

model_file = os.path.join(output_dir, "lightgbm_model.pkl")
feature_importance_file = os.path.join(output_dir, "feature_importance.csv")
threshold_file = os.path.join(output_dir, "best_threshold.json")

# ======================
# 1ï¸âƒ£ è®€å–è³‡æ–™
# ======================
print(f"ğŸ“‚ è®€å–è³‡æ–™ï¼š{train_file}")
df = pd.read_csv(train_file)

y = df["alert_flag"]
X = df.drop(columns=["acct_id", "alert_flag"])

# ======================
# 2ï¸âƒ£ è™•ç†éæ•¸å€¼æ¬„ä½
# ======================
non_numeric_cols = [c for c in X.columns if X[c].dtype not in ["int64", "float64", "bool"]]
if non_numeric_cols:
    print(f"âš ï¸ å¿½ç•¥éæ•¸å€¼æ¬„ä½ï¼š{non_numeric_cols}")
X = X.select_dtypes(include=["number", "bool"])
print(f"âœ… æœ€çµ‚ç‰¹å¾µæ•¸é‡ï¼š{X.shape[1]}")

# ======================
# 3ï¸âƒ£ åˆ†å‰²è¨“ç·´ / é©—è­‰é›†
# ======================
stratify_opt = y if y.value_counts().min() >= 2 else None
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, stratify=stratify_opt, random_state=42
)

# ======================
# 4ï¸âƒ£ å˜—è©¦ä½¿ç”¨ GPU
# ======================
device_type = "cpu"
try:
    test_params = {"device": "gpu"}
    dtest = lgb.Dataset([[0, 1], [1, 0]], label=[0, 1])
    lgb.train(test_params, dtest, num_boost_round=1)
    device_type = "gpu"
    print("âš¡ GPU å¯ç”¨ï¼Œå°‡ä½¿ç”¨ GPU åŠ é€Ÿè¨“ç·´")
except Exception:
    print("ğŸ’¡ æœªåµæ¸¬åˆ° GPUï¼Œæ”¹ç”¨ CPU æ¨¡å¼")

# ======================
# 5ï¸âƒ£ æ¨¡å‹åƒæ•¸è¨­å®š
# ======================
params = {
    "objective": "binary",
    "metric": "binary_logloss",
    "boosting_type": "gbdt",
    "num_leaves": 63,
    "learning_rate": 0.05,
    "feature_fraction": 0.8,
    "bagging_fraction": 0.8,
    "bagging_freq": 5,
    "verbosity": -1,
    "device": device_type
}

# ======================
# 6ï¸âƒ£ é–‹å§‹è¨“ç·´
# ======================
print(f"ğŸš€ é–‹å§‹è¨“ç·´ LightGBM æ¨¡å‹ ({device_type.upper()}) ...")
start = time.time()

train_data = lgb.Dataset(X_train, label=y_train)
val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

callbacks = [
    lgb.early_stopping(stopping_rounds=100),
    lgb.log_evaluation(period=200)
]

model = lgb.train(
    params=params,
    train_set=train_data,
    num_boost_round=2000,
    valid_sets=[train_data, val_data],
    valid_names=["train", "valid"],
    callbacks=callbacks
)

end = time.time()
print(f"â±ï¸ è¨“ç·´å®Œæˆï¼Œè€—æ™‚ {end - start:.2f} ç§’")

# ======================
# 7ï¸âƒ£ æ¨¡å‹è©•ä¼°èˆ‡æœ€ä½³é–¾å€¼
# ======================
print("ğŸ“Š æ¨¡å‹è©•ä¼°ä¸­ ...")
y_pred_prob = model.predict(X_val, num_iteration=model.best_iteration)
thresholds = [i / 100 for i in range(10, 91, 5)]

best_f1, best_th = 0, 0.5
for th in thresholds:
    y_pred = (y_pred_prob >= th).astype(int)
    f1 = f1_score(y_val, y_pred)
    if f1 > best_f1:
        best_f1, best_th = f1, th

y_pred = (y_pred_prob >= best_th).astype(int)
precision = precision_score(y_val, y_pred)
recall = recall_score(y_val, y_pred)
acc = accuracy_score(y_val, y_pred)
cm = confusion_matrix(y_val, y_pred)

print("\nâœ… è©•ä¼°çµæœï¼š")
print(f"Best Threshold : {best_th:.3f}")
print(f"F1 Score       : {best_f1:.4f}")
print(f"Precision      : {precision:.4f}")
print(f"Recall         : {recall:.4f}")
print(f"Accuracy       : {acc:.4f}")
print("Confusion Matrix:")
print(cm)

# ======================
# 8ï¸âƒ£ å„²å­˜æ¨¡å‹èˆ‡ç´€éŒ„
# ======================
joblib.dump(model, model_file)
print(f"\nğŸ’¾ æ¨¡å‹å·²å„²å­˜è‡³ï¼š{model_file}")

# å„²å­˜ç‰¹å¾µé‡è¦åº¦
feature_importance = pd.DataFrame({
    "feature": X.columns,
    "importance": model.feature_importance()
}).sort_values(by="importance", ascending=False)
feature_importance.to_csv(feature_importance_file, index=False)
print(f"ğŸ“Š ç‰¹å¾µé‡è¦åº¦å·²è¼¸å‡ºè‡³ï¼š{feature_importance_file}")

# å„²å­˜æœ€ä½³ threshold
with open(threshold_file, "w") as f:
    json.dump({"best_threshold": best_th}, f, indent=2)
print(f"ğŸ“ æœ€ä½³é–¾å€¼å·²å„²å­˜è‡³ï¼š{threshold_file}")
